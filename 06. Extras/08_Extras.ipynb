{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Extras"
      ],
      "metadata": {
        "id": "Lov5milgz9aZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "uOMieeuh0HkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Que tanto estoy gastando?\n",
        "\n",
        "Tenemos que [consultar la pagina](https://ai.google.dev/gemini-api/docs/pricing)  de cada proveedor y cada modelo"
      ],
      "metadata": {
        "id": "nU9mr6jO0AHN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfEiyK8wz6it"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "from pydantic import BaseModel\n",
        "from google.colab import userdata\n",
        "\n",
        "#-----------\n",
        "# todos los calculos los vamos a basar en los siguientes datos\n",
        "\n",
        "tokens = {\n",
        "    'entrada': 0,\n",
        "    'salida': 0\n",
        "}\n",
        "model = \"gemini-2.5-flash\"\n",
        "costo_por_token_entrada = 0.0000003\n",
        "costo_por_token_salida =  0.0000003\n",
        "\n",
        "def get_gasto_total():\n",
        "  return {\n",
        "      'costo' : (tokens['entrada'] * costo_por_token_entrada) + (tokens['salida'] * costo_por_token_salida),\n",
        "      'tokens': tokens['entrada'] + tokens['salida']\n",
        "  }\n",
        "#-----------\n",
        "\n",
        "# en este caso la funcion de inferencia nos permite pasar un prompt y un\n",
        "# modelo pydantic para hacer nuestra salida estructurada.\n",
        "def inferencia(content, pydantic_model):\n",
        "  client = OpenAI(\n",
        "      api_key=userdata.get('GOOGLE_API_KEY'),\n",
        "      base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        "      max_retries=2 #numero de reintentos\n",
        "  )\n",
        "\n",
        "  response = client.beta.chat.completions.parse(\n",
        "      model=model,\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": content\n",
        "          }\n",
        "      ],\n",
        "      response_format=pydantic_model\n",
        "  )\n",
        "  message = response.choices[0].message\n",
        "  tokens['entrada'] = tokens['entrada'] + response.usage.prompt_tokens\n",
        "  tokens['salida'] = tokens['salida'] + response.usage.completion_tokens\n",
        "  if message.parsed:\n",
        "    return message.parsed\n",
        "  else:\n",
        "    return message.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extraer informacion de personas"
      ],
      "metadata": {
        "id": "1QLS2h1K2g9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PersonaResponse(BaseModel):\n",
        "  nombre: str\n",
        "  edad: int\n",
        "  ciudad: str\n",
        "\n",
        "print(inferencia(\"Mi nombre es Cosme Zamudio, tengo 40 años y vivo en Mazatlan Sinaloa, Mexico.\", PersonaResponse))\n",
        "print(inferencia(\"Mi nombre es Juan Ortega, tengo 35 años y vivo en Culiacan Sinaloa, Mexico.\", PersonaResponse))\n",
        "print(inferencia(\"Mi nombre es Alan Garzon, tengo 29 años y vivo en Ciudad de Mexico.\", PersonaResponse))"
      ],
      "metadata": {
        "id": "MyOuvN0C2khR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gasto hasta ahora"
      ],
      "metadata": {
        "id": "UvzulrVw3dpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_gasto_total()"
      ],
      "metadata": {
        "id": "7hYv83uv3auL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extraccion imagen + pydantic + costos\n"
      ],
      "metadata": {
        "id": "-RoJkUzV5tID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import base64\n",
        "\n",
        "# helper para convertir el contenido de alguna url a base64\n",
        "def url_to_base64(url):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    encoded = base64.b64encode(response.content).decode('utf-8')\n",
        "    return encoded\n",
        "\n",
        "#que informacion queremos extraer de esta imagen?\n",
        "\n",
        "class CalzadoResponse(BaseModel):\n",
        "  color: str\n",
        "  color_secundario: str\n",
        "  tipo_calzado: str\n",
        "\n",
        "base64img = url_to_base64(\"https://storage.googleapis.com/tallerdp_publico/img/1000100-0001V1.jpg\")\n",
        "content = [\n",
        "  {\"type\": \"text\", \"text\": \"Del siguiente calzado extrae el color (primario), el color secundario y el tipo de calzado (tenis, zapatos, sandalias, etc)\"},\n",
        "  {\"type\": \"image_url\", \"image_url\": { \"url\" : f\"data:image/jpeg;base64,{base64img}\"}}\n",
        "]\n",
        "print(inferencia(content, CalzadoResponse))\n",
        "\n",
        "base64img = url_to_base64(\"https://storage.googleapis.com/tallerdp_publico/img/1020834-0000V1.jpg\")\n",
        "content = [\n",
        "  {\"type\": \"text\", \"text\": \"Del siguiente calzado extrae el color (primario), el color secundario y el tipo de calzado (tenis, zapatos, sandalias, etc)\"},\n",
        "  {\"type\": \"image_url\", \"image_url\": { \"url\" : f\"data:image/jpeg;base64,{base64img}\"}}\n",
        "]\n",
        "print(inferencia(content, CalzadoResponse))\n",
        "\n",
        "\n",
        "base64img = url_to_base64(\"https://storage.googleapis.com/tallerdp_publico/img/1021611-0303V1.jpg\")\n",
        "content = [\n",
        "  {\"type\": \"text\", \"text\": \"Del siguiente calzado extrae el color (primario), el color secundario y el tipo de calzado (tenis, zapatos, sandalias, etc)\"},\n",
        "  {\"type\": \"image_url\", \"image_url\": { \"url\" : f\"data:image/jpeg;base64,{base64img}\"}}\n",
        "]\n",
        "print(inferencia(content, CalzadoResponse))\n",
        "\n",
        "\n",
        "print(get_gasto_total())\n"
      ],
      "metadata": {
        "id": "QCU6Q18V6o8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Formato PDF\n",
        "\n",
        "El formato más utilizado para extraer información es el PDF, sin embargo, debemos tener en cuenta que los PDFs pueden contener texto, una imagen que se asemeje a texto o un texto.\n"
      ],
      "metadata": {
        "id": "O-kBlkqd9eVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pymupdf\n",
        "import fitz  #comentar sobre licencia\n",
        "from io import StringIO\n",
        "\n",
        "def pdf_to_text(url):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    path = \"temp.pdf\"\n",
        "    with open(path, \"wb\") as f:\n",
        "        f.write(response.content)\n",
        "\n",
        "\n",
        "    doc = fitz.open(path)\n",
        "    sb = StringIO()\n",
        "\n",
        "    for i, page in enumerate(doc, 1):\n",
        "        sb.write(f\"texto de pagina {i:02d}:\\n```\\n\")\n",
        "        sb.write(page.get_text())\n",
        "        sb.write(\"```\\n\\n\")\n",
        "    return sb.getvalue()\n",
        "\n",
        "print(pdf_to_text(\"https://storage.googleapis.com/tallerdp_publico/pdf/pdf_texto.pdf\"))"
      ],
      "metadata": {
        "id": "eCqGL_VE_IxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vamos a obtener las personas, el cargo y el numero de pagina donde se encuentra en el PDF\n",
        "from typing import List\n",
        "\n",
        "class Persona(BaseModel):\n",
        "    nombre: str\n",
        "    cargo: str\n",
        "    pagina: int\n",
        "\n",
        "class PersonasExtraidas(BaseModel):\n",
        "    personas: List[Persona]\n",
        "\n",
        "\n",
        "prompt = f\"\"\"\n",
        "Del siguiente contenido de un PDF\n",
        "\n",
        "{pdf_to_text(\"https://storage.googleapis.com/tallerdp_publico/pdf/pdf_texto.pdf\")}\n",
        "\n",
        "Extrae una lista de las personas con los siguientes datos:\n",
        "- Nombre de la persona\n",
        "- Cargo que ocupa\n",
        "- Pagina donde se encuentra\n",
        "\"\"\"\n",
        "\n",
        "print(inferencia(prompt, PersonasExtraidas))\n",
        "print(get_gasto_total())"
      ],
      "metadata": {
        "id": "zL7uRlRf_8LA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PDF como una imagen\n",
        "\n",
        "Hay casos en los que necesitamos trabajar con información visual del PDF, por ejemplo, preguntar acerca de la posición de algún elemento, logotipos o imágenes dentro del documento.\n",
        "\n",
        "Para esto, lo ideal es renderizar la página y tratarla como una imagen."
      ],
      "metadata": {
        "id": "IG72VfsEAo-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from io import BytesIO\n",
        "def pdf_url_to_base64(url):\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    pdf_stream = BytesIO(response.content)\n",
        "    doc = fitz.open(stream=pdf_stream, filetype=\"pdf\")\n",
        "    page = doc.load_page(0) #solo renderizamos la primera pagina\n",
        "    pix = page.get_pixmap(dpi=150) #es recomendable trabajr con 300 cuando hablamos de planos\n",
        "\n",
        "\n",
        "    img_bytes = pix.tobytes(\"png\")\n",
        "    encoded = base64.b64encode(img_bytes).decode(\"utf-8\")\n",
        "    return encoded\n",
        "\n",
        "\n",
        "# vamos a extraer la lista de valvulas mencionadas en el plano\n",
        "class ValvulasExtraidas(BaseModel):\n",
        "    valvulas: List[str]\n",
        "\n",
        "\n",
        "\n",
        "base64img = pdf_url_to_base64(\"https://storage.googleapis.com/tallerdp_publico/pdf/pdf_imagen.pdf\")\n",
        "content = [\n",
        "  {\"type\": \"text\", \"text\": \"Del siguiente plano, extrae todos los tipos de valcular mencionadas\"},\n",
        "  {\"type\": \"image_url\", \"image_url\": { \"url\" : f\"data:image/png;base64,{base64img}\"}}\n",
        "]\n",
        "print(inferencia(content, ValvulasExtraidas))\n",
        "print(get_gasto_total())"
      ],
      "metadata": {
        "id": "ePmE7ZejA258"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Typings y Json API\n",
        "\n",
        "[Internamente](https://github.com/openai/openai-python/blob/e68921654125ae733aac00c683b504bc89856df2/src/openai/lib/_parsing/_completions.py#L232) OpenAI convierte cualquier modelo de pydantic en Json API, usando un metodo interno.\n",
        "\n",
        "Otros metodos para generar json API:\n",
        "\n",
        "\n",
        "*   [Google AI Studio](https://ai.dev/)\n",
        "*   [OpenAI Playground](https://platform.openai.com/playground/prompts)\n",
        "\n"
      ],
      "metadata": {
        "id": "xqD1mvZ9DUqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "print(\"PersonaResponse:\")\n",
        "print(json.dumps(PersonaResponse.model_json_schema(), indent=2))\n",
        "\n",
        "print(\"CalzadoResponse:\")\n",
        "print(json.dumps(CalzadoResponse.model_json_schema(), indent=2))\n",
        "\n",
        "print(\"PersonasExtraidas:\")\n",
        "print(json.dumps(PersonasExtraidas.model_json_schema(), indent=2))\n",
        "\n",
        "print(\"ValvulasExtraidas:\")\n",
        "print(json.dumps(ValvulasExtraidas.model_json_schema(), indent=2))"
      ],
      "metadata": {
        "id": "bVP-sD1-DT_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Otros proveedores\n",
        "\n"
      ],
      "metadata": {
        "id": "m3v2SyjoFCsh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OpenRouter\n",
        "\n",
        "[OpenRouter](https://openrouter.ai/) ofrece una API unificada que te da acceso a cientos de modelos de IA a través de un solo endpoint, manejando automáticamente las alternativas y seleccionando las opciones más rentables."
      ],
      "metadata": {
        "id": "WrtFd5tSFP4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inferencia_openrouter(openrouter_model, content, pydantic_model):\n",
        "  client = OpenAI(\n",
        "      api_key=userdata.get('OPENROUTER_API_KEY'),\n",
        "      base_url=\"https://openrouter.ai/api/v1\",\n",
        "      max_retries=2 #numero de reintentos\n",
        "  )\n",
        "\n",
        "  response = client.beta.chat.completions.parse(\n",
        "      model=openrouter_model,\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": content\n",
        "          }\n",
        "      ],\n",
        "      response_format=pydantic_model\n",
        "  )\n",
        "  message = response.choices[0].message\n",
        "  if message.parsed:\n",
        "    return message.parsed\n",
        "  else:\n",
        "    return message.choices[0].message.content"
      ],
      "metadata": {
        "id": "Y9kWeaFhGo-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que tan facil es cambiar de modelo con openrouter?"
      ],
      "metadata": {
        "id": "WRKF5J0gHATJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(inferencia_openrouter(\"meta-llama/llama-3.3-8b-instruct:free\", \"Mi nombre es Cosme Zamudio, tengo 40 años y vivo en Mazatlan Sinaloa, Mexico.\", PersonaResponse))\n",
        "print(inferencia_openrouter(\"mistralai/mistral-small-3.2-24b-instruct:free\", \"Mi nombre es Juan Ortega, tengo 35 años y vivo en Culiacan Sinaloa, Mexico.\", PersonaResponse))\n",
        "print(inferencia_openrouter(\"meta-llama/llama-4-maverick:free\", \"Mi nombre es Alan Garzon, tengo 29 años y vivo en Ciudad de Mexico.\", PersonaResponse))\n",
        "\n"
      ],
      "metadata": {
        "id": "litXRAVpG_w3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Together AI\n",
        "\n",
        "Together es una plataforma que ofrece acceso directo  a modelos de lenguaje open-source como LLaMA y Mistral, ideal para quienes buscan rendimiento con pesos abiertos y posibilidad de fine-tuning; en cambio, OpenRouter actúa como un agregador que permite usar una sola API para acceder a múltiples modelos tanto open como cerrados (como GPT-4 o Claude) desde distintos proveedores, facilitando la comparación y el cambio entre ellos sin modificar el código."
      ],
      "metadata": {
        "id": "VrAIHJxoH6fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inferencia_together(together_model, content, pydantic_model):\n",
        "  client = OpenAI(\n",
        "      api_key=userdata.get('TOGETHERAI_API_KEY'),\n",
        "      base_url=\"https://api.together.xyz/v1\",\n",
        "      max_retries=2 #numero de reintentos\n",
        "  )\n",
        "\n",
        "  response = client.beta.chat.completions.parse(\n",
        "      model=together_model,\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": content\n",
        "          }\n",
        "      ],\n",
        "      response_format=pydantic_model\n",
        "  )\n",
        "  message = response.choices[0].message\n",
        "  if message.parsed:\n",
        "    return message.parsed\n",
        "  else:\n",
        "    return message.choices[0].message.content\n",
        "\n",
        "\n",
        "print(inferencia_together(\"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\", \"Mi nombre es Alan Garzon, tengo 29 años y vivo en Ciudad de Mexico.\", PersonaResponse))"
      ],
      "metadata": {
        "id": "QVmp90VeISkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Podemos abstraer nuestra funcion de inferencia de la siguiente manera:\n"
      ],
      "metadata": {
        "id": "dI9fabySJL1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def infer(content, pydantic_model, model = \"gpt-4.1-mini\", api_key=userdata.get('OPENAI_API_KEY'), base_url='https://api.openai.com/v1'):\n",
        "  client = OpenAI(\n",
        "      api_key=api_key,\n",
        "      base_url=base_url,\n",
        "      max_retries=2\n",
        "  )\n",
        "\n",
        "  response = client.beta.chat.completions.parse(\n",
        "      model=model,\n",
        "      messages=[\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": content\n",
        "          }\n",
        "      ],\n",
        "      response_format=pydantic_model\n",
        "  )\n",
        "  message = response.choices[0].message\n",
        "  if message.parsed:\n",
        "    return message.parsed\n",
        "  else:\n",
        "    return message.choices[0].message.content\n",
        "\n",
        "#OPENAI\n",
        "print(infer(\"Mi nombre es Alan Garzon, tengo 29 años y vivo en Ciudad de Mexico.\", PersonaResponse))\n",
        "#TOGETHERAI\n",
        "print(infer(\"Mi nombre es Alan Garzon, tengo 29 años y vivo en Ciudad de Mexico.\",\n",
        "            PersonaResponse,\n",
        "            model = 'meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo',\n",
        "            api_key=userdata.get('TOGETHERAI_API_KEY'),\n",
        "            base_url='https://api.together.xyz/v1'))\n",
        "#CEREBRAS\n",
        "print(infer(\"Mi nombre es Alan Garzon, tengo 29 años y vivo en Ciudad de Mexico.\",\n",
        "            PersonaResponse,\n",
        "            model = 'llama-4-scout-17b-16e-instruct',\n",
        "            api_key=userdata.get('CEREBRAS_API_KEY'),\n",
        "            base_url='https://api.cerebras.ai/v1'))"
      ],
      "metadata": {
        "id": "a8-qbLiWJLYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio Final"
      ],
      "metadata": {
        "id": "7U-Fai66Msn1"
      }
    }
  ]
}